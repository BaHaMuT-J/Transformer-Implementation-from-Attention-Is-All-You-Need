{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eb8ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from minbpe import BasicTokenizer\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import  Dataset, DataLoader\n",
    "\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e12e01",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc74f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"abisee/cnn_dailymail\", \"3.0.0\")\n",
    "\n",
    "# Save to disk\n",
    "# ds.save_to_disk(\"data/cnn_dailymail_dataset\")\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97234a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 287113\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 13368\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 11490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you already save to disk\n",
    "ds = load_from_disk(\"data/cnn_dailymail_dataset\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14e95a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['article', 'highlights'],\n",
       "     num_rows: 287113\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['article', 'highlights'],\n",
       "     num_rows: 13368\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['article', 'highlights'],\n",
       "     num_rows: 11490\n",
       " }))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = ds['train'].select_columns([\"article\", \"highlights\"])\n",
    "val_data = ds['validation'].select_columns([\"article\", \"highlights\"])\n",
    "test_data = ds['test'].select_columns([\"article\", \"highlights\"])\n",
    "train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1503fb1d",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643ad841",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8452af7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3530528"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The data used for training\n",
    "all_articles_text = \" \".join(train_data[\"article\"][:1000])\n",
    "len(all_articles_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2b373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BasicTokenizer()\n",
    "tokenizer.train(all_articles_text, vocab_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e25f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[76, 79, 78, 68, 79]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how it encode\n",
    "encoded_article_0 = tokenizer.encode(train_data['article'][0])\n",
    "encoded_article_0[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0875b4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe\\'s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say \\'kid star goes off the rails,\\'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter\\'s latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer\\'s \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he\\'s legally an adult: \"I just think I\\'m going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.',\n",
       " True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how it decode\n",
    "decoded_article_0 = tokenizer.decode(encoded_article_0)\n",
    "decoded_article_0, decoded_article_0 == train_data['article'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2275d418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add special tokens, we do not need <unk> here because data is in english and fit in ASCII\n",
    "max_vocab_id = list(tokenizer.vocab.keys())[-1]\n",
    "tokenizer.special_tokens = {\n",
    "    \"<sos>\": max_vocab_id + 1,\n",
    "    \"<eos>\": max_vocab_id + 2,\n",
    "    \"<unk>\": max_vocab_id + 3,\n",
    "    \"<pad>\": max_vocab_id + 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b78ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<sos> LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe\\'s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say \\'kid star goes off the rails,\\'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter\\'s latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer\\'s \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he\\'s legally an adult: \"I just think I\\'m going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed. <eos> <pad> <pad>',\n",
       " True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how it works with special tokens\n",
    "encoded_special_0 = tokenizer.encode(f\"<sos> {train_data['article'][0]} <eos> <pad> <pad>\")\n",
    "decoded_special_0 = tokenizer.decode(encoded_special_0)\n",
    "decoded_special_0, decoded_special_0 == f\"<sos> {train_data['article'][0]} <eos> <pad> <pad>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1f5d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to disk\n",
    "tokenizer.save(\"model/model_article_1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c101fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from disk\n",
    "tokenizer = BasicTokenizer()\n",
    "tokenizer.load(\"model/model_article_1000.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883b59bb",
   "metadata": {},
   "source": [
    "### Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884bc133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fields(example):\n",
    "    example[\"article\"] = tokenizer.encode(example[\"article\"])\n",
    "    example[\"highlights\"] = tokenizer.encode(example[\"highlights\"])\n",
    "    return example\n",
    "\n",
    "# Tokenize each split\n",
    "train_tokenized = train_data.select(range(10_000)).map(tokenize_fields)\n",
    "val_tokenized = val_data.select(range(2500)).map(tokenize_fields)\n",
    "test_tokenized = test_data.select(range(2500)).map(tokenize_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db2f5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to disk\n",
    "train_tokenized.save_to_disk(\"data/cnn_train_tokenized_10k\")\n",
    "val_tokenized.save_to_disk(\"data/cnn_val_tokenized_2500\")\n",
    "test_tokenized.save_to_disk(\"data/cnn_test_tokenized_2500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffd69a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you already save to disk\n",
    "train_tokenized = load_from_disk(\"data/cnn_train_tokenized_10k\")\n",
    "val_tokenized = load_from_disk(\"data/cnn_val_tokenized_2500\")\n",
    "test_tokenized = load_from_disk(\"data/cnn_test_tokenized_2500\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d77b17",
   "metadata": {},
   "source": [
    "## Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec568f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorizer:\n",
    "  def __init__(self, tokenizer: BasicTokenizer):\n",
    "    self.tokenizer = tokenizer\n",
    "    self.vocab_size = len(tokenizer.vocab)\n",
    "    self.sos_idx = tokenizer.special_tokens[\"<sos>\"]\n",
    "    self.eos_idx = tokenizer.special_tokens[\"<eos>\"]\n",
    "    self.pad_idx = tokenizer.special_tokens[\"<pad>\"]\n",
    "\n",
    "  # Add <sos> and <eos> at the start and end, pad data if necessasry\n",
    "  def index_vectorize(self, tokens, max_length=1024):\n",
    "    indices = tokens[:max_length - 2]\n",
    "    indices = [self.sos_idx] + indices + [self.eos_idx]\n",
    "    indices += [self.pad_idx] * (max_length - len(indices))\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55d1b19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_vectorizer = Vectorizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "674a996c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos>LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe\\'s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say \\'kid star goes off the rails,\\'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter\\'s latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer\\'s \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he\\'s legally an adult: \"I just think I\\'m going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.<eos><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(article_vectorizer.index_vectorize(encoded_article_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b23f27d",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "610deb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexArticleDataset(Dataset):\n",
    "  def __init__(self, input, target, vectorizer: Vectorizer, max_input_length=1024, max_target_length=128):\n",
    "    self.input = input\n",
    "    self.target = target\n",
    "    self.vectorizer = vectorizer\n",
    "    \n",
    "    self.max_input_length = max_input_length\n",
    "    self.max_target_length = max_target_length\n",
    "    \n",
    "    self.sos_index = vectorizer.sos_idx\n",
    "    self.eos_index = vectorizer.eos_idx\n",
    "    self.pad_index = vectorizer.pad_idx\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.input)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return {'x': torch.as_tensor(self.vectorizer.index_vectorize(self.input[index], self.max_input_length)),\n",
    "            'y': torch.as_tensor(self.vectorizer.index_vectorize(self.target[index], self.max_target_length))}\n",
    "\n",
    "  def get_vectorizer(self):\n",
    "    return self.vectorizer \n",
    "  \n",
    "  def get_num_batches(self, batch_size):\n",
    "    return len(self) // batch_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1ae289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = IndexArticleDataset(train_tokenized['article'], \n",
    "                                    train_tokenized['highlights'], \n",
    "                                    article_vectorizer,\n",
    "                                    max_input_length=512,\n",
    "                                    max_target_length=128)\n",
    "\n",
    "val_dataset = IndexArticleDataset(val_tokenized['article'], \n",
    "                                  val_tokenized['highlights'], \n",
    "                                  article_vectorizer,\n",
    "                                  max_input_length=512,\n",
    "                                  max_target_length=128)\n",
    "\n",
    "test_dataset = IndexArticleDataset(test_tokenized['article'], \n",
    "                                   test_tokenized['highlights'], \n",
    "                                   article_vectorizer,\n",
    "                                   max_input_length=512,\n",
    "                                   max_target_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4e698974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 128)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dict = train_dataset.__getitem__(0)\n",
    "len(out_dict['x']), len(out_dict['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4379d294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<sos>LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Rad<eos>',\n",
       " \"<sos>Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\\nYoung actor says he has no plans to fritter his cash away .\\nRadcliffe's earnings from first five Potter films have been held in trust fund .<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(out_dict['x'].numpy()), tokenizer.decode(out_dict['y'].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6407bc",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d7cab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(dataset, batch_size, \n",
    "                     shuffle=True,\n",
    "                     drop_last=True, \n",
    "                     device=\"cpu\"):\n",
    "  \n",
    "  dataloader = DataLoader(dataset=dataset, \n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle, \n",
    "                          drop_last=drop_last)\n",
    "\n",
    "  for data_dict in dataloader:\n",
    "    out_data_dict = {}\n",
    "    for name, tensor in data_dict.items():\n",
    "      out_data_dict[name] = data_dict[name].to(device)\n",
    "    yield out_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7fc1b81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([32, 512]), y shape: torch.Size([32, 128])\n",
      "tensor([[1024,   40,   69,  ...,   78,  900, 1025],\n",
      "        [1024,   40,   84,  ...,  401,  276, 1025],\n",
      "        [1024,   78,   69,  ..., 1027, 1027, 1027],\n",
      "        ...,\n",
      "        [1024,   76,   79,  ...,  735,  373, 1025],\n",
      "        [1024,  702,   65,  ...,  456,  412, 1025],\n",
      "        [1024,  651,   32,  ...,  926,  549, 1025]])\n",
      "tensor([[1024,   69,  115,  ..., 1027, 1027, 1027],\n",
      "        [1024,   65,   99,  ..., 1027, 1027, 1027],\n",
      "        [1024,   80,  304,  ...,  331,   67, 1025],\n",
      "        ...,\n",
      "        [1024,   82,  265,  ..., 1027, 1027, 1027],\n",
      "        [1024,   78,   69,  ..., 1027, 1027, 1027],\n",
      "        [1024,   75,  612,  ...,  334,  473, 1025]])\n"
     ]
    }
   ],
   "source": [
    "# Using generate_batches to get 1 sample at a time\n",
    "for out_dict in generate_batches(dataset=train_dataset, batch_size=32):\n",
    "  x_data = out_dict['x']\n",
    "  y_target = out_dict['y']\n",
    "  print(f\"x shape: {x_data.shape}, y shape: {y_target.shape}\")\n",
    "  print(x_data)\n",
    "  print(y_target)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6123f56",
   "metadata": {},
   "source": [
    "## Model & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f567a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f710b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "  def __init__(self, embed_dim, head_dim, max_input_length, dropout=0.5, is_masked=True):\n",
    "    super().__init__()\n",
    "    self.key = nn.Linear(embed_dim, head_dim, bias=False)\n",
    "    self.query = nn.Linear(embed_dim, head_dim, bias=False)\n",
    "    self.value = nn.Linear(embed_dim, head_dim, bias=False)\n",
    "    self.is_masked = is_masked\n",
    "    if is_masked:\n",
    "      self.register_buffer('mask', torch.tril(torch.ones(max_input_length, max_input_length)))\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    B, T, C = x.shape # (batch_size, time_steps, channels=embed_dim)\n",
    "\n",
    "    K = self.key(x)\n",
    "    Q = self.query(x)\n",
    "\n",
    "    KQ = (Q @ K.transpose(-2, -1)) \n",
    "    KQ_normalized = KQ / (np.sqrt(K.shape[-1]))\n",
    "    if self.is_masked:\n",
    "      KQ_normalized = KQ_normalized.masked_fill(self.mask[:T, :T] == 0, float('-inf'))\n",
    "    KQ_normalized_masked_softmaxed = torch.softmax(KQ_normalized, dim=-1)\n",
    "    KQ_normalized_masked_softmaxed_dropouted = self.dropout(KQ_normalized_masked_softmaxed)\n",
    "\n",
    "    V = self.value(x)\n",
    "    out = KQ_normalized_masked_softmaxed_dropouted @ V\n",
    "    return out\n",
    "  \n",
    "class MultiHeadAttention(nn.Module):\n",
    "  def __init__(self, num_heads, embed_dim, max_input_length, dropout=0.5, is_masked=True):\n",
    "    super().__init__()\n",
    "    head_dim = embed_dim // num_heads\n",
    "    self.heads = nn.ModuleList([Head(embed_dim, head_dim, max_input_length, dropout, is_masked) for _ in range(num_heads)])\n",
    "    self.linear = nn.Linear(head_dim * num_heads, embed_dim)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "    out = self.linear(out)\n",
    "    out = self.dropout(out)\n",
    "    return out\n",
    "  \n",
    "class FeedFoward(nn.Module):\n",
    "  def __init__(self, embed_dim, dropout=0.5):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Linear(embed_dim, 4*embed_dim), # default: embed_dim=512, feed_forward_dim=2048)\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(4*embed_dim, embed_dim),\n",
    "      nn.Dropout(dropout),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.layers(x)\n",
    "  \n",
    "class SubLayer(nn.Module):\n",
    "  def __init__(self, layer: nn.Module, embed_dim):\n",
    "    super().__init__()\n",
    "    self.Layer = layer\n",
    "    self.ln = nn.LayerNorm(embed_dim)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.ln(x + self.Layer(x)) # normalization after residual connection\n",
    "    return out\n",
    "  \n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, num_heads, embed_dim, max_input_length, dropout=0.5):\n",
    "    super().__init__()\n",
    "    self.multi_head_attention = SubLayer(MultiHeadAttention(num_heads, embed_dim, max_input_length, dropout, is_masked=False), embed_dim)\n",
    "    self.feed_forward = SubLayer(FeedFoward(embed_dim, dropout), embed_dim)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.multi_head_attention(x)\n",
    "    out = self.feed_forward(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3199dc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 512, 512]),\n",
       " tensor([[[ 0.6405, -0.1673,  1.5610,  ..., -1.5898,  2.7004,  1.2969],\n",
       "          [ 0.8247, -2.4709, -1.2504,  ..., -0.8810, -0.5874, -1.6542],\n",
       "          [ 2.9421,  0.5028, -0.1382,  ..., -0.0732, -1.9269, -0.1504],\n",
       "          ...,\n",
       "          [-4.5145,  2.2122,  1.4346,  ...,  1.3832,  3.5295, -3.6478],\n",
       "          [-0.6273,  0.3386,  0.1103,  ..., -1.1479,  1.1510, -0.9009],\n",
       "          [-3.4660,  0.1393,  3.3567,  ...,  1.1316,  3.6283,  0.0147]],\n",
       " \n",
       "         [[-3.3873, -0.4156,  0.4918,  ...,  0.0259,  1.5445,  3.3582],\n",
       "          [ 0.1686,  4.2974,  1.2911,  ..., -2.2388,  0.6872, -0.2633],\n",
       "          [-1.6014, -0.5566,  3.7714,  ...,  0.8337, -0.1632, -1.3584],\n",
       "          ...,\n",
       "          [ 0.5006, -0.2951, -2.3882,  ...,  1.0986, -0.7568,  1.6341],\n",
       "          [-0.8417, -2.5384,  0.3607,  ...,  1.3841, -0.2138,  3.9314],\n",
       "          [-1.1533, -0.3058,  2.7287,  ...,  1.2510,  3.5344,  0.7337]],\n",
       " \n",
       "         [[ 2.1097,  1.4932,  0.4418,  ..., -2.0781,  3.0396,  0.5167],\n",
       "          [-1.0020,  0.0657, -0.4704,  ..., -0.7546, -3.5015, -2.0128],\n",
       "          [-0.1164, -0.7052,  1.7689,  ...,  1.1477,  1.3747, -1.3284],\n",
       "          ...,\n",
       "          [-1.0837,  1.2758,  0.6170,  ..., -1.5460,  0.8731,  1.5737],\n",
       "          [-0.5085,  0.9121, -0.8300,  ...,  0.2758, -0.1913, -0.9977],\n",
       "          [-1.7468, -0.5594,  1.8439,  ...,  1.1839,  0.5092, -0.4253]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.0860,  2.2798, -0.9848,  ..., -1.5401,  0.7271, -0.3194],\n",
       "          [ 3.8424,  0.3686, -1.8420,  ..., -0.8255, -0.2951, -2.4323],\n",
       "          [ 0.9107, -1.1244, -0.6577,  ..., -0.6199, -3.3744, -0.6228],\n",
       "          ...,\n",
       "          [-1.8856, -1.3324,  0.2113,  ...,  0.5584, -0.7584, -0.8134],\n",
       "          [-1.6451,  1.3480,  0.7305,  ..., -1.0673,  0.1454,  2.3620],\n",
       "          [-2.5389, -0.5431,  2.0983,  ...,  1.2616,  3.5204,  1.5458]],\n",
       " \n",
       "         [[-2.4689,  2.3552,  4.6466,  ..., -2.7732,  2.1608, -2.6795],\n",
       "          [ 0.2177, -1.6111, -0.0210,  ...,  0.6383,  0.5481,  0.3471],\n",
       "          [-1.3482,  0.2457,  1.2591,  ...,  0.8406,  1.8682,  1.8229],\n",
       "          ...,\n",
       "          [-1.2473,  1.9427, -2.2866,  ..., -0.5453, -0.2654,  0.2018],\n",
       "          [-3.5577,  1.9700,  2.1525,  ...,  0.8232,  0.4601, -2.3033],\n",
       "          [-3.9644,  1.3876,  1.4308,  ...,  2.0124,  0.9980, -0.8804]],\n",
       " \n",
       "         [[ 0.6676, -0.2350,  1.5548,  ..., -1.6574,  1.3114, -0.7693],\n",
       "          [ 3.6541, -1.2759, -2.1640,  ..., -1.5224, -1.9955, -3.4644],\n",
       "          [-0.6685, -1.5972,  0.0210,  ...,  0.0860, -1.7677, -1.7824],\n",
       "          ...,\n",
       "          [ 0.5266,  2.1529, -0.9970,  ..., -0.5953, -2.1361,  2.0882],\n",
       "          [-0.7532,  0.8448,  0.7392,  ...,  1.0485, -2.0340, -2.8170],\n",
       "          [-4.3910, -0.5910,  5.2303,  ...,  1.7067,  0.6354, -0.8417]]],\n",
       "        grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_input_length = 512\n",
    "max_target_length = 128\n",
    "batch_size = 32\n",
    "\n",
    "vocab_size = len(tokenizer.vocab)\n",
    "num_heads = 8\n",
    "embed_dim = 512\n",
    "dropout = 0.5\n",
    "\n",
    "model = Encoder(num_heads, embed_dim, max_input_length, dropout)\n",
    "embed = nn.Embedding(vocab_size, embed_dim, padding_idx=article_vectorizer.pad_idx)\n",
    "for out_dict in generate_batches(dataset=train_dataset, batch_size=batch_size):\n",
    "  output = model(embed(out_dict['x']))\n",
    "  break\n",
    "output.shape, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "268250f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 512, 512]),\n",
       " tensor([[[-3.2848e-03, -6.2605e-01,  3.2050e+00,  ...,  2.8122e+00,\n",
       "            8.4817e-01,  4.2711e-01],\n",
       "          [ 1.5457e+00,  1.5078e+00, -5.5269e-01,  ...,  1.7982e+00,\n",
       "            1.1940e+00,  5.9078e-01],\n",
       "          [ 1.2618e+00, -4.9616e-01, -3.4182e+00,  ..., -7.2561e-01,\n",
       "            2.7547e+00, -1.4425e+00],\n",
       "          ...,\n",
       "          [-1.7603e+00, -1.8944e+00,  2.3924e+00,  ..., -1.3581e-01,\n",
       "            8.2968e-01, -2.5232e+00],\n",
       "          [-5.3222e-01, -7.9528e-01,  5.1655e-01,  ...,  1.3098e+00,\n",
       "           -1.6992e+00,  1.6046e+00],\n",
       "          [ 1.6983e+00, -1.1008e+00,  2.2834e-01,  ...,  6.8362e-01,\n",
       "           -7.9560e-01, -2.7744e+00]],\n",
       " \n",
       "         [[ 4.6308e-02, -5.7645e-01,  1.6314e+00,  ...,  1.0671e+00,\n",
       "           -6.3364e-02, -1.9410e+00],\n",
       "          [ 2.4141e+00,  1.4357e+00,  2.4945e+00,  ...,  5.2852e-01,\n",
       "           -8.9884e-02,  1.8258e-01],\n",
       "          [-1.7752e-01,  2.3532e-01, -7.8018e-01,  ..., -6.5597e-02,\n",
       "           -2.2782e-01,  1.0101e+00],\n",
       "          ...,\n",
       "          [ 3.9601e-01,  2.8606e-01,  6.9362e-01,  ..., -2.2572e-01,\n",
       "           -8.6735e-01,  1.4239e+00],\n",
       "          [ 1.6638e-01, -5.5937e-01, -4.4756e-01,  ...,  8.6402e-01,\n",
       "            1.4469e+00, -7.0083e-01],\n",
       "          [ 2.1019e+00, -1.1619e+00,  1.9174e-01,  ...,  2.3231e+00,\n",
       "            2.3957e+00, -1.2851e+00]],\n",
       " \n",
       "         [[ 6.7518e-01, -6.4412e-01,  3.3157e+00,  ...,  2.9365e+00,\n",
       "           -1.3103e-01,  4.0903e-01],\n",
       "          [ 1.5356e+00,  1.4374e+00, -5.6279e-01,  ..., -2.9098e-01,\n",
       "            1.3935e+00,  5.4344e-01],\n",
       "          [-3.3218e-01, -3.1804e-01, -7.0796e-01,  ..., -1.1575e+00,\n",
       "            1.1193e+00, -2.4810e-01],\n",
       "          ...,\n",
       "          [ 5.1512e-01,  2.1263e+00, -1.0760e+00,  ...,  2.4395e-01,\n",
       "           -1.7024e+00, -5.3218e-01],\n",
       "          [-1.2644e+00,  1.9091e+00, -1.1097e+00,  ...,  2.5077e-01,\n",
       "           -1.3826e-01,  2.3805e-01],\n",
       "          [ 2.1092e+00, -1.1544e+00,  5.7005e-01,  ...,  6.5558e-01,\n",
       "           -6.1316e-01, -2.7029e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 9.9611e-04,  3.8067e-01,  3.1948e+00,  ...,  2.8005e+00,\n",
       "            8.4387e-01, -1.8843e+00],\n",
       "          [ 1.7941e+00,  1.3157e+00,  2.3395e+00,  ..., -2.9392e-01,\n",
       "           -1.7203e+00, -1.5554e+00],\n",
       "          [ 7.1299e-01,  7.1067e-03, -1.7089e+00,  ...,  4.5949e+00,\n",
       "           -4.1017e-01, -3.1167e-01],\n",
       "          ...,\n",
       "          [ 6.5561e-01,  4.5722e-01, -5.4450e-01,  ..., -5.5930e-01,\n",
       "           -5.9405e-01, -2.9396e-01],\n",
       "          [ 1.2203e+00,  4.9288e-01,  2.0093e-01,  ...,  1.0782e+00,\n",
       "            1.6614e+00,  1.9844e+00],\n",
       "          [ 1.6864e+00, -1.1247e+00,  2.1643e-01,  ...,  2.4050e+00,\n",
       "            2.4204e+00, -2.7398e+00]],\n",
       " \n",
       "         [[ 2.5514e-02, -5.9725e-01,  3.4025e+00,  ...,  3.0276e+00,\n",
       "            9.7687e-01,  4.5590e-01],\n",
       "          [ 2.3463e+00,  1.4044e+00,  4.3218e+00,  ...,  4.9695e-01,\n",
       "            2.0675e-02,  1.5128e-01],\n",
       "          [ 4.0676e-01, -1.2343e+00,  5.4484e-01,  ...,  1.2364e+00,\n",
       "            1.2057e+00, -1.0966e-01],\n",
       "          ...,\n",
       "          [-1.2297e+00,  5.6508e-01,  7.9703e-01,  ..., -6.7874e-01,\n",
       "           -3.8021e-01,  2.4558e-02],\n",
       "          [-7.6211e-01, -2.0309e-01,  6.7392e-01,  ...,  8.7872e-01,\n",
       "            1.0508e+00, -4.4718e-01],\n",
       "          [ 2.1015e+00, -1.1656e+00,  5.5900e-01,  ...,  2.3789e+00,\n",
       "            2.3753e+00, -2.8011e+00]],\n",
       " \n",
       "         [[ 6.1777e-01, -6.6691e-01,  3.2059e+00,  ...,  9.7665e-01,\n",
       "           -1.5382e-01, -2.0103e+00],\n",
       "          [ 1.5186e+00,  1.5045e+00, -1.0613e+00,  ..., -3.0795e-01,\n",
       "            1.3936e+00, -1.0981e-01],\n",
       "          [-1.2808e+00, -3.4042e-01, -8.5280e-01,  ...,  6.7432e-01,\n",
       "            1.3213e+00, -2.7048e-01],\n",
       "          ...,\n",
       "          [ 2.7768e+00, -8.7183e-01,  1.3567e+00,  ..., -8.5096e-01,\n",
       "           -1.7085e-01, -1.3630e+00],\n",
       "          [ 5.9406e-01,  1.1860e+00, -1.2172e-01,  ...,  2.5013e+00,\n",
       "            1.4380e+00, -3.4698e+00],\n",
       "          [ 1.6833e+00, -1.5070e+00,  6.0105e-01,  ...,  6.6854e-01,\n",
       "            2.4172e+00, -2.7595e+00]]], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SubLayer(FeedFoward(embed_dim, dropout), embed_dim)\n",
    "embed = nn.Embedding(vocab_size, embed_dim, padding_idx=article_vectorizer.pad_idx)\n",
    "for out_dict in generate_batches(dataset=train_dataset, batch_size=32):\n",
    "  output = model(embed(out_dict['x']))\n",
    "  break\n",
    "output.shape, output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScienceClass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
